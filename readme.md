# 使用 python 下载整个网站小说

---

## 项目介绍

本项目使用python，调用python中与爬虫有关的库，对网络小说网站进行爬取，将小说信息保存在数据库中，并将小说文件下载到本地。

**本项目主要针对 `http://wap.xqishuta.com/` 网站进行开发，不保证适配其他网站**

* 本项目调用python中相关库进行所有操作
* 支持使用第三方代理进行爬取操作，防止被网站屏蔽
* 使用MySQL保存所有信息

## 文件简介

### Dir.py

用于检测目录是否存在，并创建相关目录

主要用于保存小说文件

### Download.py

用于下载文件

其中，`cmd_path`用于表明本地wget程序路径（本项目使用wget进行下载操作）。

`http_proxy`表示本地代理信息

### Logger.py

用于保存日志信息

### MySql.py

所有对数据库的操作。用于保存小说的各项信息。

```python
sqlname = "数据库名"
password = "数据库密码"
table = "表名"
host = "数据库地址"
```

### Process.py

对网站进行爬取的所有操作。

### Main.py

项目主文件。

